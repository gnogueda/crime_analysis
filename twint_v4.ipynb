{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cbee1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a6531b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sophielogan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sophielogan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import twint\n",
    "import datetime as dt \n",
    "import os \n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "nest_asyncio.apply() # for working in jupyter notebooks \n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stopwords = stopwords.words('english')\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55782455",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('/users/sophielogan/Desktop/tweets_downloads/20200406chicago.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb99c4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shooting OR killed OR kill OR shot OR gun OR rifle OR pistol OR murder OR murdered OR murderers OR violence OR violent OR attack OR mug OR mugged OR mugging OR assault OR assaulted OR assaulting OR criminal OR criminals OR harass OR harassment OR sexual OR rape OR rapist OR raped OR raping OR hit OR punch OR punched OR kick OR stab OR weapon OR knife OR wound OR hurt OR injured OR wounded OR offense'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's keep it in 45 words. We can loop every vocabulary\n",
    "potential_crime_string = '''shooting killed kill shot gun rifle pistol murder murdered murderers violence violent attack mug mugged mugging assault assaulted assaulting criminal criminals harass harassment sexual rape rapist raped\n",
    "raping hit punch punched kick stab weapon knife wound hurt injured wounded offense'''\n",
    "''' felony misdemeanor law abuse force''' # battered'''\n",
    "#potential_crime_string = '''gang band danger dangerous kidnap kidnapped kidnapping robber robbery steal stole stolen hijacking victim\n",
    "#victims trafficking bomb police fbi death dead died die\n",
    "#'''\n",
    "pcs_split = potential_crime_string.split()\n",
    "print(len(pcs_split))\n",
    "pcs_split_or = \" OR \".join(pcs_split)\n",
    "pcs_split_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab25bede",
   "metadata": {},
   "outputs": [],
   "source": [
    "social = '''sociable, gregarious societal friendly society socialization political  sociality \n",
    "                        interpersonal  ethnic socially party welfare public community socialist societies development\n",
    "                            network humans socialism collective personal corporation social constructivism\n",
    "                        relations volition citizenship brute   attitude rights socio \n",
    "                        socioeconomic ethics civic communal marital  sociale socialized communities     \n",
    "                         policy   unions        \n",
    "                        institutions values     governmental   organizations jamboree \n",
    "                         festivity    fairness  support  care  \n",
    "                         sides   activism     unsocial psychosocial \n",
    "                        socializing psychological distributional  demographic  participation reunion \n",
    "                        partygoer partyism festive power network gala housewarming celebration counterparty   social-war\n",
    "                        particularist interactional ideational asocial'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef17e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "health = '''disease obesity world health organization medicine nutrition well-being exercise welfare wellness health care public health \n",
    "                     nursing stress safety hygiene research social healthy condition aids epidemiology healthiness wellbeing\n",
    "                     care illness medical dieteducation infectious disease environmental healthcare physical fitness hospitals \n",
    "                     health care provider doctors healthy community design insurance sanitation human body patient mental health\n",
    "                      medicare agriculture health science fitnesshealth policy  weight loss physical therapy psychology pharmacy\n",
    "                     metabolic organism human lifestyle status unhealthy upbeat vaccination sleep condom alcohol smoking water family\n",
    "                     eudaimonia eudaemonia air house prevention genetics public families poor needs treatment communicable disease \n",
    "                     study protection malaria development food priority management healthful mental provide department administration\n",
    "                     programs help assistance funding environment improving emergency need program affected schools private mental illness \n",
    "                     treat diseases preparedness perinatal fertility sickness veterinary sanitary pharmacists behavioral midwives\n",
    "                     gerontology infertility hospitalization midwifery cholesterol childcare pediatrician pediatrics medicaid asthma \n",
    "                     pensions sicknesses push-up physical education body-mass-index eat well gymnastic apparatus tune up good morning \n",
    "                     bathing low blood-pressure heart attack health club ride-bike you feel good eczema urticaria dermatitis sunburn overwork \n",
    "                     manufacturing medical sociology need exercise run'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58afc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Vectorizing the sets of words, then standardizing them. TFIDF will be used in order to take care of the least \n",
    "frequent words. Standardizing is cause TFIDF favors long sentences and there'll be inconsistencies between the length \n",
    "of the tweets and the length of set of words.'''\n",
    "\n",
    "def get_vectors(*strs):\n",
    "    text = [t for t in strs]\n",
    "    vectorizer = TfidfVectorizer(text)\n",
    "    vectorizer.fit(text)\n",
    "    return vectorizer.transform(text).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cf719ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sophielogan/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass input=['sociable, gregarious societal friendly society socialization political  sociality \\n                        interpersonal  ethnic socially party welfare public community socialist societies development\\n                            network humans socialism collective personal corporation social constructivism\\n                        relations volition citizenship brute   attitude rights socio \\n                        socioeconomic ethics civic communal marital  sociale socialized communities     \\n                         policy   unions        \\n                        institutions values     governmental   organizations jamboree \\n                         festivity    fairness  support  care  \\n                         sides   activism     unsocial psychosocial \\n                        socializing psychological distributional  demographic  participation reunion \\n                        partygoer partyism festive power network gala housewarming celebration counterparty   social-war\\n                        particularist interactional ideational asocial'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "/Users/sophielogan/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass input=['disease obesity world health organization medicine nutrition well-being exercise welfare wellness health care public health \\n                     nursing stress safety hygiene research social healthy condition aids epidemiology healthiness wellbeing\\n                     care illness medical dieteducation infectious disease environmental healthcare physical fitness hospitals \\n                     health care provider doctors healthy community design insurance sanitation human body patient mental health\\n                      medicare agriculture health science fitnesshealth policy  weight loss physical therapy psychology pharmacy\\n                     metabolic organism human lifestyle status unhealthy upbeat vaccination sleep condom alcohol smoking water family\\n                     eudaimonia eudaemonia air house prevention genetics public families poor needs treatment communicable disease \\n                     study protection malaria development food priority management healthful mental provide department administration\\n                     programs help assistance funding environment improving emergency need program affected schools private mental illness \\n                     treat diseases preparedness perinatal fertility sickness veterinary sanitary pharmacists behavioral midwives\\n                     gerontology infertility hospitalization midwifery cholesterol childcare pediatrician pediatrics medicaid asthma \\n                     pensions sicknesses push-up physical education body-mass-index eat well gymnastic apparatus tune up good morning \\n                     bathing low blood-pressure heart attack health club ride-bike you feel good eczema urticaria dermatitis sunburn overwork \\n                     manufacturing medical sociology need exercise run'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "socialvector = get_vectors(social)\n",
    "healthvector = get_vectors(health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590b8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    if type(tweet) == np.float:\n",
    "        return \"\"\n",
    "    temp = tweet.lower()\n",
    "    temp = re.sub(\"'\", \"\", temp) # to avoid removing contractions in english\n",
    "    temp = re.sub(\"@[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(\"#[A-Za-z0-9_]+\",\"\", temp)\n",
    "    temp = re.sub(r'http\\S+', '', temp)\n",
    "    temp = re.sub('[()!?]', ' ', temp)\n",
    "    temp = re.sub('\\[.*?\\]',' ', temp)\n",
    "    temp = re.sub(\"[^a-z0-9]\",\" \", temp)\n",
    "    temp = temp.split()\n",
    "    temp = [w for w in temp if not w in stopwords]\n",
    "    temp = \" \".join(word for word in temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175a75c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-a6606d7cc17b>:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if type(tweet) == np.float:\n"
     ]
    }
   ],
   "source": [
    "def clean_all_tweets(frame):\n",
    "    frame['tweet'] = frame['tweet'].map(lambda x: clean_tweet(x))\n",
    "    \n",
    "clean_all_tweets(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc75076e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     yes even kill nobody gone see em win win regar...\n",
       "1     one thing never understood purge everyone want...\n",
       "2                              kill local indie softboy\n",
       "3                        government issued getting shot\n",
       "4                      1 good gun never worry money smh\n",
       "                            ...                        \n",
       "95                                     ooh one hit home\n",
       "96    never drinking 4 loko ever life shit almost ki...\n",
       "97                                            hit lmfao\n",
       "98    attack time full creativity keep innovative mi...\n",
       "99    part dealing pandemic one thing major thing co...\n",
       "Name: tweet, Length: 100, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "875df830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sophielogan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "<ipython-input-13-d3918884e414>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['sentiment'][idx] = sentiment_names[index]\n",
      "/Users/sophielogan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "\n",
    "def sentiment(df): \n",
    "    sid = SentimentIntensityAnalyzer() # Calculate neutral, negative and positive sentiment scores and label tweet with highest sentiment \n",
    "    df['sentiment'] = np.nan\n",
    "    for idx, tweet in enumerate(df['tweet']):\n",
    "        sentiment_dict = sid.polarity_scores(tweet)\n",
    "        sentiment_names = ('Negative', 'Positive', 'Neutral')\n",
    "        sentiment_tup = (sentiment_dict['neg'], sentiment_dict['pos'], sentiment_dict['neu'])\n",
    "        if np.any(sentiment_tup) > 0.0: # if all values are 0, leave label as nan \n",
    "            index = sentiment_tup.index(max(sentiment_tup))\n",
    "            df['sentiment'][idx] = sentiment_names[index]  \n",
    "            \n",
    "sentiment(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32778654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mentions any items in dictionary, count 1 \n",
    "def naive_count(category, tweet): \n",
    "    for word in tweet: \n",
    "        if word in category:\n",
    "            return 1 \n",
    "        return 0 \n",
    "\n",
    "frame['naive count social'] = frame['tweet'].map(lambda x: naive_count(social, x))\n",
    "frame['naive count health'] = frame['tweet'].map(lambda x: naive_count(health, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfbf0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorizing the tweets\n",
    "tv=TfidfVectorizer()\n",
    "# tweets_bowl = tweets_bowl.tweets.apply(get_vectors)\n",
    "# tweets_bowl.head()\n",
    "tfidf_tweets =tv.fit_transform(frame.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0dafe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Jaccard similarity is good for cases where duplication does not matter, \n",
    "cosine similarity is good for cases where duplication matters while analyzing text similarity. For two product descriptions, \n",
    "it will be better to use Jaccard similarity as repetition of a word does not reduce their similarity.'''\n",
    "\n",
    "def jaccard_similarity(query, document):\n",
    "    intersection = set(query).intersection(set(document))\n",
    "    union = set(query).union(set(document))\n",
    "    return len(intersection)/len(union)\n",
    "# jaccard_score(socialvector, economic_vector)\n",
    "\n",
    "#for similarity of 1 and 2 of column1\n",
    "# jaccard_similarity('dog lion a dog','dog is cat')\n",
    "def get_scores(title, group, frame):\n",
    "    frame[f'jaccard sim score {title}'] = frame['tweet'].map(lambda x: jaccard_similarity(group,x))\n",
    "\n",
    "get_scores('social',social,frame)\n",
    "get_scores('health',health,frame)\n",
    "\n",
    "#def get_scores(group,tweets):\n",
    "#    scores = []\n",
    "#    for tweet in tweets:\n",
    "#        s = jaccard_similarity(group, tweet)\n",
    "#        scores.append(s)\n",
    "#    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70d23dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>jaccard sim score social</th>\n",
       "      <th>jaccard sim score health</th>\n",
       "      <th>naive count social</th>\n",
       "      <th>naive count health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1247312570698084352</td>\n",
       "      <td>1247309890554560512</td>\n",
       "      <td>2020-04-06 18:57:45 CDT</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>18:57:45</td>\n",
       "      <td>-600</td>\n",
       "      <td>3388071358</td>\n",
       "      <td>pamperedone</td>\n",
       "      <td>Tiffany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'screen_name': 'kiss_myROSE', 'name': 'üëë Sha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247312303218966528</td>\n",
       "      <td>1247312303218966528</td>\n",
       "      <td>2020-04-06 18:56:41 CDT</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>18:56:41</td>\n",
       "      <td>-600</td>\n",
       "      <td>334571553</td>\n",
       "      <td>jae_khaliah</td>\n",
       "      <td>‚òÄÔ∏éÔ∏é JA√â KHALIAH ‚òΩ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1247311806806319115</td>\n",
       "      <td>1247300921354223619</td>\n",
       "      <td>2020-04-06 18:54:43 CDT</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>18:54:43</td>\n",
       "      <td>-600</td>\n",
       "      <td>3301158974</td>\n",
       "      <td>miserabletop</td>\n",
       "      <td>jared ‚ù§Ô∏è‚Äçüî•</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'screen_name': 'MarshallIversen', 'name': 'M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1247310908172439554</td>\n",
       "      <td>1247310908172439554</td>\n",
       "      <td>2020-04-06 18:51:09 CDT</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>18:51:09</td>\n",
       "      <td>-600</td>\n",
       "      <td>2784851391</td>\n",
       "      <td>ededdnedgar</td>\n",
       "      <td>Investor Ed üèöüè¢üè¶üí∞üìàüìô</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1247309543157178369</td>\n",
       "      <td>1247307527592837120</td>\n",
       "      <td>2020-04-06 18:45:43 CDT</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>18:45:43</td>\n",
       "      <td>-600</td>\n",
       "      <td>1028356298503532555</td>\n",
       "      <td>diegoo_dela</td>\n",
       "      <td>lover boy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'screen_name': 'CeetTheKid', 'name': 'ceetot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id               created_at  \\\n",
       "0  1247312570698084352  1247309890554560512  2020-04-06 18:57:45 CDT   \n",
       "1  1247312303218966528  1247312303218966528  2020-04-06 18:56:41 CDT   \n",
       "2  1247311806806319115  1247300921354223619  2020-04-06 18:54:43 CDT   \n",
       "3  1247310908172439554  1247310908172439554  2020-04-06 18:51:09 CDT   \n",
       "4  1247309543157178369  1247307527592837120  2020-04-06 18:45:43 CDT   \n",
       "\n",
       "         date      time  timezone              user_id      username  \\\n",
       "0  2020-04-06  18:57:45      -600           3388071358   pamperedone   \n",
       "1  2020-04-06  18:56:41      -600            334571553   jae_khaliah   \n",
       "2  2020-04-06  18:54:43      -600           3301158974  miserabletop   \n",
       "3  2020-04-06  18:51:09      -600           2784851391   ededdnedgar   \n",
       "4  2020-04-06  18:45:43      -600  1028356298503532555   diegoo_dela   \n",
       "\n",
       "                 name place  ...  \\\n",
       "0             Tiffany   NaN  ...   \n",
       "1   ‚òÄÔ∏éÔ∏é JA√â KHALIAH ‚òΩ   NaN  ...   \n",
       "2          jared ‚ù§Ô∏è‚Äçüî•   NaN  ...   \n",
       "3  Investor Ed üèöüè¢üè¶üí∞üìàüìô   NaN  ...   \n",
       "4           lover boy   NaN  ...   \n",
       "\n",
       "                                            reply_to retweet_date translate  \\\n",
       "0  [{'screen_name': 'kiss_myROSE', 'name': 'üëë Sha...          NaN       NaN   \n",
       "1                                                 []          NaN       NaN   \n",
       "2  [{'screen_name': 'MarshallIversen', 'name': 'M...          NaN       NaN   \n",
       "3                                                 []          NaN       NaN   \n",
       "4  [{'screen_name': 'CeetTheKid', 'name': 'ceetot...          NaN       NaN   \n",
       "\n",
       "  trans_src trans_dest  sentiment  jaccard sim score social  \\\n",
       "0       NaN        NaN   Positive                  0.607143   \n",
       "1       NaN        NaN    Neutral                  0.750000   \n",
       "2       NaN        NaN   Negative                  0.535714   \n",
       "3       NaN        NaN    Neutral                  0.500000   \n",
       "4       NaN        NaN   Positive                  0.482759   \n",
       "\n",
       "   jaccard sim score health naive count social naive count health  \n",
       "0                  0.629630                  1                  1  \n",
       "1                  0.777778                  1                  1  \n",
       "2                  0.555556                  1                  1  \n",
       "3                  0.518519                  1                  1  \n",
       "4                  0.500000                  0                  0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81743d8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# social scores\n",
    "#s_scores1 = get_scores(social, frame.tweet.to_list())\n",
    "#s_scores2 = get_scores(health, frame.tweet.to_list())\n",
    "#print(s_scores1[:10])\n",
    "#print(s_scores2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame['murder score'] = s_scores1\n",
    "#frame['rape score'] = s_scores2\n",
    "#frame['robbery score'] = s_scores3\n",
    "#frame['aggravated assault score'] = s_scores4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48690631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary \n",
    "#'theft':['grand theft auto','putin is a murderer','murder raste'],'rape':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4521a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine rather than Jaccard \n",
    "# Similarity \n",
    "# Use TF, not TFIDF -- TFIDF is for longer documents, not to small strings like twitter \n",
    "# Add counter as well to compare to TF \n",
    "\n",
    "# Very simple way to do topic modelling - rather than LDA \n",
    "# Put LDA topic modelling code and then say this helped guide us to do manual dictionary for topic models \n",
    "\n",
    "# Merge based on year \n",
    "\n",
    "\n",
    "# Visuals\n",
    "# bar chart: x axis = city, y axis = avg norm measure, and then bars 1st bar actual measure (fbi), second bar sentiment, third bar normalized tweet count\n",
    "# line graph see how each metric tracks over time\n",
    "# map of cities and do it for metric seperateky\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later analysis \n",
    "\n",
    "# Normalization after merging (normalize by population, divide by max (max ratio in any city) to make it standardized) \n",
    "\n",
    "# Use frame.near to get city \n",
    "#tweets_agg = tweets_df.groupby(['city','year']).mean()\n",
    "\n",
    "#fbi_df.merge(tweets_agg,\n",
    "#            how = 'left',\n",
    "#            left_on = ['city','year'],\n",
    "#            right_on = ['city','year'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
